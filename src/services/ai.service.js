// src/services/ai.service.js - VERSI√ìN CORREGIDA CON HISTORIAL PERSISTENTE
import dotenv from "dotenv";
dotenv.config();

import { GoogleGenerativeAI } from "@google/generative-ai";
import { getPromptConfig } from "../prompts/prompt-loader.js";
import { buildPrompt, sanitizeGeminiApiKey } from "../utils/ai.utils.js";
import {
  saveMessage,
  getConversationHistory,
  formatHistoryForPrompt,
  getHistoryStats
} from "./conversation-history.service.js";

const RAW_KEY = process.env.GEMINI_API_KEY || "";
const API_KEY = sanitizeGeminiApiKey(RAW_KEY);

if (!API_KEY || !API_KEY.startsWith("AIza")) {
  console.error("‚ùå GEMINI_API_KEY inv√°lida o vac√≠a. Revisa tu .env");
}

const genAI = new GoogleGenerativeAI(API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
const multimodalModel = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
const audioReplyModel = genAI.getGenerativeModel({
  model: "gemini-2.0-flash",
  generationConfig: {
    responseMimeType: "audio/mpeg",
  },
});

export async function generateAIReply({ text, conversationContext = null, phone = null }) {
  // 1. RECUPERAR HISTORIAL DESDE SUPABASE
  let contextPrompt = "";
  
  if (phone) {
    const history = await getConversationHistory(phone, 15); // √öltimos 15 mensajes
    
    if (history.length > 0) {
      contextPrompt = formatHistoryForPrompt(history);
      
      // A√±adir estad√≠sticas de la conversaci√≥n
      const stats = await getHistoryStats(phone);
      if (stats) {
        contextPrompt += `\nESTAD√çSTICAS:\n`;
        contextPrompt += `- Mensajes totales: ${stats.totalMessages}\n`;
        contextPrompt += `- Edad de conversaci√≥n: ${stats.conversationAge} minutos\n`;
        if (stats.lastIntent) {
          contextPrompt += `- √öltima intenci√≥n: ${stats.lastIntent}\n`;
        }
      }
    }
  }
  
  // 2. A√ëADIR CONTEXTO DEL ESTADO
  if (conversationContext) {
    contextPrompt += `\nCONTEXTO ADICIONAL:\n`;
    if (conversationContext.isHumanHandling) {
      contextPrompt += `- ‚ö†Ô∏è Un humano acaba de manejar esta conversaci√≥n\n`;
    }
    if (conversationContext.awaitingScheduling) {
      contextPrompt += `- üìÖ El cliente estaba en proceso de agendamiento\n`;
    }
    if (conversationContext.lastIntent) {
      contextPrompt += `- üéØ √öltima intenci√≥n detectada: ${conversationContext.lastIntent}\n`;
    }
    if (conversationContext.servicePreference) {
      const label = conversationContext.servicePreference === 'therapy'
        ? 'terapia psicol√≥gica'
        : 'consulta psiqui√°trica';
      contextPrompt += `- ‚úÖ El cliente indic√≥ inter√©s en ${label}\n`;
    }
  }

  try {
    // 3. GENERAR RESPUESTA CON CONTEXTO COMPLETO
    const { prompt: businessPrompt, versionTag, source } = await getPromptConfig();
    const input = buildPrompt({ businessPrompt, contextPrompt, text });

    console.log(`üß† Generando respuesta (prompt v=${versionTag}, source=${source}) para ${phone || 'desconocido'}`);

    const result = await model.generateContent({
      contents: [{ parts: [{ text: input }] }],
    });
    
    let out = result.response.text().trim();
    out = out.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim();

    const lines = out.split("\n");
    let rawJson = lines[lines.length - 1];
    
    let jsonFound = false;
    for (let i = lines.length - 1; i >= 0; i--) {
      if (lines[i].trim().startsWith("{") && lines[i].includes('"intent"')) {
        rawJson = lines[i].trim();
        lines.splice(i, 1);
        jsonFound = true;
        break;
      }
    }
    
    let message = lines.join("\n").trim();

    let meta = {
      intent: "info",
      priority: "low",
      notify_human: false,
      service: null,
      suggested_actions: [],
      confidence: 0.6,
    };
    
    try {
      const cleanJson = rawJson.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      meta = JSON.parse(cleanJson);
    } catch (parseError) {
      console.error("‚ùå Error parseando JSON de IA:", parseError.message);
      try {
        const intentMatch = rawJson.match(/"intent"\s*:\s*"([^"]+)"/);
        const priorityMatch = rawJson.match(/"priority"\s*:\s*"([^"]+)"/);
        const notifyMatch = rawJson.match(/"notify_human"\s*:\s*(true|false)/);
        const serviceMatch = rawJson.match(/"service"\s*:\s*"([^"]+)"/);
        
        if (intentMatch) meta.intent = intentMatch[1];
        if (priorityMatch) meta.priority = priorityMatch[1];
        if (notifyMatch) meta.notify_human = notifyMatch[1] === 'true';
        if (serviceMatch) meta.service = serviceMatch[1] === 'null' ? null : serviceMatch[1];
      } catch (e) {
        console.error("‚ùå Error en extracci√≥n manual de meta:", e.message);
      }
    }

    // CORRECCI√ìN: Fallback de mensaje si est√° vac√≠o
    const MIN_MESSAGE_LENGTH = 4;
    if (!message || message.length < MIN_MESSAGE_LENGTH) {
      console.warn(`‚ö†Ô∏è Mensaje de IA vac√≠o o muy corto. Generando fallback conversacional.`);
      
      switch (meta.intent) {
        case 'agendar':
          message = "¬°Perfecto! Un momento por favor, te env√≠o la informaci√≥n para agendar tu cita. üòä";
          break;
        case 'precios':
        case 'servicios':
          message = "Claro, con gusto te doy la informaci√≥n. ¬øCu√°l de nuestros servicios te interesa? üíô";
          break;
        case 'horarios':
          message = "Nuestros horarios son L-V 9AM-8PM y S√°b 9AM-2PM. ¬øTe gustar√≠a agendar una cita? ‚ú®";
          break;
        case 'despedida':
          message = "Gracias por contactarnos. ¬°Que tengas un excelente d√≠a! üòä";
          break;
        default:
          message = "Hola, soy el asistente de Feliz Horizonte. ¬øEn qu√© puedo ayudarte hoy? üòä";
          break;
      }
      
      if (meta.intent === 'saludo' || meta.intent === 'despedida' || meta.intent === 'error') {
        meta.intent = 'info';
        meta.confidence = 0.5;
      }
    }
    
    // Detecci√≥n manual de servicio si la IA fall√≥
    if (!meta.service || meta.service === 'null') {
      const textLower = text.toLowerCase();
      if (/(psicolog[√≠i]a|psic[√≥o]log[oa]|terapia|terapeuta)/i.test(textLower)) {
        meta.service = 'therapy';
        console.log(`üîß Detecci√≥n manual: servicio = therapy`);
      } else if (/(psiquiatr[√≠i]a|psiquiatra)/i.test(textLower)) {
        meta.service = 'psychiatry';
        console.log(`üîß Detecci√≥n manual: servicio = psychiatry`);
      }
    }

    if (conversationContext?.servicePreference && (!meta.service || meta.service === 'null')) {
      meta.service = conversationContext.servicePreference;
      console.log(`üîß Override: servicio definido por botones = ${meta.service}`);
    }

    // Si detecta "agendar" + "therapy", NO derivar a humano
    if (meta.intent === 'agendar' && meta.service === 'therapy') {
      meta.notify_human = false;
      console.log(`üîß Override: agendamiento de terapia = auto-respuesta`);
    }

    // L√≥gica de frustraci√≥n
    const frustrationKeywords = [
      'ya te dije', 'ya dije', 'ya lo mencion√©', 'repites', 'otra vez',
      'me ibas', 'ibas a', 'dijiste que', 'prometiste', 'cansado',
      'molesto', 'fastidioso', 'in√∫til'
    ];
    
    const textLower = text.toLowerCase();
    const isFrustrated = frustrationKeywords.some(keyword => textLower.includes(keyword));
    
    if (isFrustrated) {
      meta.notify_human = true;
      meta.priority = 'high';
      console.log(`‚ö†Ô∏è Frustraci√≥n detectada en: "${text}"`);
    }

    // Si el cliente menciona "hoy" o "ahora", derivar a humano
    if (/\b(hoy|ahora|ahorita|ya|inmediato)\b/i.test(text) && 
        (meta.intent === 'agendar' || meta.intent === 'horarios')) {
      meta.notify_human = true;
      console.log(`‚ö†Ô∏è Solicitud urgente detectada: "${text}"`);
    }

    // 4. GUARDAR EN HISTORIAL PERSISTENTE
    if (phone) {
      await saveMessage({
        phone,
        role: 'user',
        content: text,
        intent: null,
        service: meta.service
      });

      await saveMessage({
        phone,
        role: 'assistant',
        content: message,
        intent: meta.intent,
        service: meta.service
      });
    }

    console.log(`üìä Meta final:`, JSON.stringify(meta));

    return { message, meta };
  } catch (e) {
    console.error("‚ùå AI error:", e?.message);
    return {
      message:
        "Gracias por escribirnos üòä En este momento estoy teniendo dificultades t√©cnicas. Un miembro de mi equipo te atender√° en breve.",
      meta: {
        intent: "error",
        priority: "high",
        notify_human: true,
        service: null,
        suggested_actions: [],
        confidence: 0.1,
      },
    };
  }
}

export async function transcribeAudioBuffer({ buffer, mimeType = "audio/ogg", prompt = null }) {
  if (!buffer || !buffer.length) {
    throw new Error("Audio buffer vac√≠o");
  }

  const instruction =
    prompt ||
    "Transcribe con precisi√≥n este audio, conserva la puntuaci√≥n natural y no agregues comentarios adicionales.";

  try {
    const response = await multimodalModel.generateContent({
      contents: [
        {
          role: "user",
          parts: [
            { text: instruction },
            {
              inlineData: {
                data: buffer.toString("base64"),
                mimeType,
              },
            },
          ],
        },
      ],
    });

    const transcription = response?.response?.text?.() || response?.response?.text || "";
    return (typeof transcription === "function" ? transcription() : transcription)?.trim() || "";
  } catch (err) {
    console.error("‚ùå Error transcribiendo audio:", err?.message);
    throw err;
  }
}

export async function synthesizeAudioFromText(text, { promptPrefix = null } = {}) {
  const cleanText = (text || "").trim();
  if (!cleanText) {
    throw new Error("Texto vac√≠o para sintetizar audio");
  }

  const prompt =
    promptPrefix ||
    "Convierte el texto a un mensaje de voz claro, c√°lido y profesional en espa√±ol peruano.";

  try {
    const response = await audioReplyModel.generateContent({
      contents: [
        {
          role: "user",
          parts: [{ text: `${prompt}\n\nTexto:\n${cleanText}` }],
        },
      ],
    });

    const audioPart = response?.response?.candidates
      ?.flatMap((candidate) => candidate?.content?.parts || [])
      ?.find((part) => part.inlineData?.data);

    if (!audioPart?.inlineData?.data) {
      throw new Error("La IA no devolvi√≥ audio");
    }

    return {
      buffer: Buffer.from(audioPart.inlineData.data, "base64"),
      mimeType: audioPart.inlineData.mimeType || "audio/mpeg",
    };
  } catch (err) {
    console.error("‚ùå Error generando audio:", err?.message);
    throw err;
  }
}